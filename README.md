# LLM

This repository contains a from-scratch implementation of a GPT-like Large Language Model (LLM) using PyTorch.
The implementation is based on the book [Build a Large Language Model (From Scratch)](https://www.manning.com/books/build-a-large-language-model-from-scratch) by Sebastian Raschka.
For learning purposes only.  

## Overview

This project demonstrates the step-by-step process of building a transformer-based language model similar to GPT 
(Generative Pre-trained Transformer). It covers key concepts including:

-Transformer achitecture  
-Self-attention mechanisms  
-Token embedding  
-Positional encodings  

## Installation

Run the following command to clone the repo:

```
git clone https://github.com/DraganAleksic99/llm.git
```

Install dependencies:

```
cd llm
pip install -r requirements.txt
```
